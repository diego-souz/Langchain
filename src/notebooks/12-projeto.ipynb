{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores.chroma import Chroma\n",
    "\n",
    "from langchain_community.document_loaders.pdf import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 16 0 (offset 0)\n",
      "Ignoring wrong pointing object 18 0 (offset 0)\n",
      "Ignoring wrong pointing object 20 0 (offset 0)\n",
      "Ignoring wrong pointing object 22 0 (offset 0)\n",
      "Ignoring wrong pointing object 42 0 (offset 0)\n",
      "Ignoring wrong pointing object 50 0 (offset 0)\n",
      "Ignoring wrong pointing object 52 0 (offset 0)\n",
      "Ignoring wrong pointing object 54 0 (offset 0)\n",
      "Ignoring wrong pointing object 56 0 (offset 0)\n",
      "Ignoring wrong pointing object 58 0 (offset 0)\n",
      "Ignoring wrong pointing object 70 0 (offset 0)\n",
      "Ignoring wrong pointing object 72 0 (offset 0)\n",
      "Ignoring wrong pointing object 89 0 (offset 0)\n",
      "Ignoring wrong pointing object 91 0 (offset 0)\n",
      "Ignoring wrong pointing object 103 0 (offset 0)\n",
      "Ignoring wrong pointing object 108 0 (offset 0)\n",
      "Ignoring wrong pointing object 149 0 (offset 0)\n",
      "Ignoring wrong pointing object 155 0 (offset 0)\n",
      "Ignoring wrong pointing object 158 0 (offset 0)\n",
      "Ignoring wrong pointing object 160 0 (offset 0)\n",
      "Ignoring wrong pointing object 163 0 (offset 0)\n",
      "Ignoring wrong pointing object 165 0 (offset 0)\n"
     ]
    }
   ],
   "source": [
    "caminhos = [\n",
    "    \"../../assets/pdf/apostila.pdf\",\n",
    "    \"../../assets/pdf/LLM.pdf\",\n",
    "    ]\n",
    "\n",
    "paginas = []\n",
    "for caminho in caminhos:\n",
    "    loader = PyPDFLoader(caminho)\n",
    "    paginas.extend(loader.load())\n",
    "\n",
    "recur_split = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=100,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"]\n",
    ")\n",
    "\n",
    "documents = recur_split.split_documents(paginas)\n",
    "\n",
    "for i, doc in enumerate(documents):\n",
    "    doc.metadata['source'] = doc.metadata['source'].replace('arquivos/', '')\n",
    "    doc.metadata['doc_id'] = i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "diretorio = 'arquivos/chat_retrieval_db'\n",
    "\n",
    "embeddings_model = OpenAIEmbeddings()\n",
    "vectordb = Chroma.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=embeddings_model,\n",
    "    persist_directory=diretorio\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI(model=\"gpt-4o-mini\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.retrieval_qa.base import RetrievalQA\n",
    "\n",
    "chat_chain = RetrievalQA.from_chain_type(\n",
    "    llm=chat,\n",
    "    retriever=vectordb.as_retriever(search_type='mmr'),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'O que é Hugging Face e como faço para acessá-lo?',\n",
       " 'result': 'Hugging Face é uma empresa que desenvolve e mantém uma plataforma e uma biblioteca de modelos de aprendizado de máquina, especialmente focada em processamento de linguagem natural (NLP). A biblioteca mais conhecida é o Transformers, que permite o uso de modelos pré-treinados para tarefas como tradução, geração de texto e classificação.\\n\\nPara acessar o Hugging Face, você pode visitar o site oficial em [huggingface.co](https://huggingface.co), onde você encontrará uma variedade de modelos e ferramentas. Além disso, você pode instalar a biblioteca Transformers em seu ambiente Python usando o seguinte comando:\\n\\n```bash\\npip install transformers\\n```\\n\\nApós a instalação, você pode começar a usar os modelos disponíveis na biblioteca dentro do seu código Python.'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pergunta = \"O que é Hugging Face e como faço para acessá-lo?\"\n",
    "chat_chain.invoke({\"query\": pergunta})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "chain_prompt = PromptTemplate.from_template(\n",
    "\"\"\"Utilize o contexto fornecido para responder a pergunta ao final. \n",
    "Se você não sabe a resposta, apenas diga que não sabe e não invente uma resposta.\n",
    "Utilize três frases no máximo, mantenha a resposta concisa.\n",
    "\n",
    "Contexto: {context}\n",
    "\n",
    "Pergunta: {question}\n",
    "\n",
    "Resposta:\n",
    "\"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_chain = RetrievalQA.from_chain_type(\n",
    "    llm=chat,\n",
    "    retriever=vectordb.as_retriever(search_type=\"mmr\"),\n",
    "    chain_type_kwargs={\"prompt\":chain_prompt},\n",
    "    return_source_documents=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face é uma plataforma que oferece uma biblioteca de modelos de aprendizado de máquina, especialmente para processamento de linguagem natural. Você pode acessá-lo através de seu site e utilizar seus modelos com suporte a frameworks de código aberto como o MLflow. É possível encontrar e integrar modelos em seu ambiente de programação, facilitando o uso para desenvolvedores.\n"
     ]
    }
   ],
   "source": [
    "pergunta = 'O que é Hugging Face e como faço para acessá-lo?'\n",
    "resposta = chat_chain.invoke({'query': pergunta})\n",
    "print(resposta['result'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Atualmente, requer um pouco mais de esforço para pegar um modelo de código aberto e começar a usá-lo, mas o progresso está ocorrendo muito rapidamente para torná-los mais acessíveis aos usuários. Na Databricks, por exemplo, fizemos melhorias em frameworks de código aberto como o MLflow para tornar muito fácil para alguém com um pouco de experiência em Python pegar qualquer modelo transformador da Hugging Face e usá-lo como um objeto Python. Muitas vezes, você pode encontrar um modelo de código aberto que resolve seu problema específico e que é várias ordens de grandeza menor que o ChatGPT, permitindo que você traga o modelo para seu ambiente e hospede-o você mesmo. Isso significa que você pode manter os dados sob seu controle para preocupações com privacidade e governança, além de gerenciar seus custos. Outra grande vantagem de usar modelos de código aberto é a capacidade de ajustá-los aos seus próprios dados', metadata={'doc_id': 75, 'page': 6, 'source': '../../assets/pdf/LLM.pdf'}),\n",
       " Document(page_content='E-BOOK Um guia compacto sobre Large Language Models (LLM)', metadata={'doc_id': 55, 'page': 0, 'source': '../../assets/pdf/LLM.pdf'}),\n",
       " Document(page_content='. Outras implementações notáveis de IA generativa incluem projetos como a geração de arte a partir de texto, áudio e vídeo, e certamente muitas outras novidades surgirão em breve.', metadata={'doc_id': 58, 'page': 1, 'source': '../../assets/pdf/LLM.pdf'}),\n",
       " Document(page_content='>>> hello()  \\nOlá Mundo!!!  \\n \\n \\n11.2 Parâmetros e a rgumentos  \\n \\n Parâmetros são as variáveis que podem ser incluídas nos parênteses das funções . Quando a \\nfunção é chamada são passados valores para essas variáveis. E sses valores são chamados \\nargumentos. O corpo da função pode utilizar essas variáveis, cujos valores podem modificar o \\ncomportamento da função.  \\n \\nExemplo:  Função para imprimir  o maior entre 2 valores  \\n \\ndef maior(x,y): \\n    if x>y: \\n        print(x) \\n    else: \\n        print(y) \\n \\n>>> maior(4,7)  \\n7', metadata={'doc_id': 46, 'page': 21, 'source': '../../assets/pdf/apostila.pdf'})]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resposta['source_documents']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RetrievalQA] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"query\": \"O que é Hugging Face e como faço para acessá-lo?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:StuffDocumentsChain] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:StuffDocumentsChain > chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"O que é Hugging Face e como faço para acessá-lo?\",\n",
      "  \"context\": \"Atualmente, requer um pouco mais de esforço para pegar um modelo de código aberto e começar a usá-lo, mas o progresso está ocorrendo muito rapidamente para torná-los mais acessíveis aos usuários. Na Databricks, por exemplo, fizemos melhorias em frameworks de código aberto como o MLflow para tornar muito fácil para alguém com um pouco de experiência em Python pegar qualquer modelo transformador da Hugging Face e usá-lo como um objeto Python. Muitas vezes, você pode encontrar um modelo de código aberto que resolve seu problema específico e que é várias ordens de grandeza menor que o ChatGPT, permitindo que você traga o modelo para seu ambiente e hospede-o você mesmo. Isso significa que você pode manter os dados sob seu controle para preocupações com privacidade e governança, além de gerenciar seus custos. Outra grande vantagem de usar modelos de código aberto é a capacidade de ajustá-los aos seus próprios dados\\n\\nE-BOOK Um guia compacto sobre Large Language Models (LLM)\\n\\n. Outras implementações notáveis de IA generativa incluem projetos como a geração de arte a partir de texto, áudio e vídeo, e certamente muitas outras novidades surgirão em breve.\\n\\n>>> hello()  \\nOlá Mundo!!!  \\n \\n \\n11.2 Parâmetros e a rgumentos  \\n \\n Parâmetros são as variáveis que podem ser incluídas nos parênteses das funções . Quando a \\nfunção é chamada são passados valores para essas variáveis. E sses valores são chamados \\nargumentos. O corpo da função pode utilizar essas variáveis, cujos valores podem modificar o \\ncomportamento da função.  \\n \\nExemplo:  Função para imprimir  o maior entre 2 valores  \\n \\ndef maior(x,y): \\n    if x>y: \\n        print(x) \\n    else: \\n        print(y) \\n \\n>>> maior(4,7)  \\n7\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:StuffDocumentsChain > chain:LLMChain > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: Utilize o contexto fornecido para responder a pergunta ao final. \\nSe você não sabe a resposta, apenas diga que não sabe e não invente uma resposta.\\nUtilize três frases no máximo, mantenha a resposta concisa.\\n\\nContexto: Atualmente, requer um pouco mais de esforço para pegar um modelo de código aberto e começar a usá-lo, mas o progresso está ocorrendo muito rapidamente para torná-los mais acessíveis aos usuários. Na Databricks, por exemplo, fizemos melhorias em frameworks de código aberto como o MLflow para tornar muito fácil para alguém com um pouco de experiência em Python pegar qualquer modelo transformador da Hugging Face e usá-lo como um objeto Python. Muitas vezes, você pode encontrar um modelo de código aberto que resolve seu problema específico e que é várias ordens de grandeza menor que o ChatGPT, permitindo que você traga o modelo para seu ambiente e hospede-o você mesmo. Isso significa que você pode manter os dados sob seu controle para preocupações com privacidade e governança, além de gerenciar seus custos. Outra grande vantagem de usar modelos de código aberto é a capacidade de ajustá-los aos seus próprios dados\\n\\nE-BOOK Um guia compacto sobre Large Language Models (LLM)\\n\\n. Outras implementações notáveis de IA generativa incluem projetos como a geração de arte a partir de texto, áudio e vídeo, e certamente muitas outras novidades surgirão em breve.\\n\\n>>> hello()  \\nOlá Mundo!!!  \\n \\n \\n11.2 Parâmetros e a rgumentos  \\n \\n Parâmetros são as variáveis que podem ser incluídas nos parênteses das funções . Quando a \\nfunção é chamada são passados valores para essas variáveis. E sses valores são chamados \\nargumentos. O corpo da função pode utilizar essas variáveis, cujos valores podem modificar o \\ncomportamento da função.  \\n \\nExemplo:  Função para imprimir  o maior entre 2 valores  \\n \\ndef maior(x,y): \\n    if x>y: \\n        print(x) \\n    else: \\n        print(y) \\n \\n>>> maior(4,7)  \\n7\\n\\nPergunta: O que é Hugging Face e como faço para acessá-lo?\\n\\nResposta:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:StuffDocumentsChain > chain:LLMChain > llm:ChatOpenAI] [1.53s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Hugging Face é uma plataforma que oferece uma vasta coleção de modelos de aprendizado de máquina, especialmente para processamento de linguagem natural. Você pode acessar os modelos através do site da Hugging Face e utilizá-los em seu ambiente Python, muitas vezes com ferramentas como o MLflow para facilitar a integração. É recomendável ter alguma experiência em Python para começar a usar os modelos.\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Hugging Face é uma plataforma que oferece uma vasta coleção de modelos de aprendizado de máquina, especialmente para processamento de linguagem natural. Você pode acessar os modelos através do site da Hugging Face e utilizá-los em seu ambiente Python, muitas vezes com ferramentas como o MLflow para facilitar a integração. É recomendável ter alguma experiência em Python para começar a usar os modelos.\",\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 76,\n",
      "                \"prompt_tokens\": 461,\n",
      "                \"total_tokens\": 537,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 0\n",
      "                }\n",
      "              },\n",
      "              \"model_name\": \"gpt-4o-mini\",\n",
      "              \"system_fingerprint\": \"fp_0392822090\",\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-87c522a5-8008-41d3-86ad-169356f70c38-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 76,\n",
      "      \"prompt_tokens\": 461,\n",
      "      \"total_tokens\": 537,\n",
      "      \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      },\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_name\": \"gpt-4o-mini\",\n",
      "    \"system_fingerprint\": \"fp_0392822090\"\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:StuffDocumentsChain > chain:LLMChain] [1.53s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \"Hugging Face é uma plataforma que oferece uma vasta coleção de modelos de aprendizado de máquina, especialmente para processamento de linguagem natural. Você pode acessar os modelos através do site da Hugging Face e utilizá-los em seu ambiente Python, muitas vezes com ferramentas como o MLflow para facilitar a integração. É recomendável ter alguma experiência em Python para começar a usar os modelos.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:StuffDocumentsChain] [1.53s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output_text\": \"Hugging Face é uma plataforma que oferece uma vasta coleção de modelos de aprendizado de máquina, especialmente para processamento de linguagem natural. Você pode acessar os modelos através do site da Hugging Face e utilizá-los em seu ambiente Python, muitas vezes com ferramentas como o MLflow para facilitar a integração. É recomendável ter alguma experiência em Python para começar a usar os modelos.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RetrievalQA] [2.54s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n"
     ]
    }
   ],
   "source": [
    "from langchain.globals import set_debug\n",
    "\n",
    "set_debug(True)\n",
    "\n",
    "pergunta = 'O que é Hugging Face e como faço para acessá-lo?'\n",
    "resposta = chat_chain.invoke({'query': pergunta})\n",
    "\n",
    "set_debug(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face é uma plataforma que oferece uma ampla gama de modelos de aprendizado de máquina, especialmente voltados para processamento de linguagem natural (NLP), incluindo Large Language Models (LLMs). Além disso, a Hugging Face também está se expandindo para outras áreas de IA generativa, como a geração de arte a partir de texto, áudio e vídeo, entre outras inovações que estão surgindo.\n",
      "\n",
      "Para acessar o Hugging Face e explorar os LLMs e outros projetos de IA generativa, você pode seguir os seguintes passos:\n",
      "\n",
      "1. **Visite o site**: Acesse o site oficial do Hugging Face em [huggingface.co](https://huggingface.co).\n",
      "\n",
      "2. **Crie uma conta**: Você pode criar uma conta gratuita para acessar mais recursos e funcionalidades, como a possibilidade de salvar seus próprios modelos ou anotações.\n",
      "\n",
      "3. **Explore os modelos**: No site, você pode navegar pela biblioteca de modelos disponíveis, onde pode filtrar por tarefa, linguagem e tipo de modelo, incluindo LLMs e outros projetos de IA generativa.\n",
      "\n",
      "4. **Utilize a biblioteca Transformers**: Para usar os modelos em seu código, você pode instalar a biblioteca Transformers através do pip com o comando:\n",
      "   ```bash\n",
      "   pip install transformers\n",
      "   ```\n",
      "\n",
      "5. **Consulte a documentação**: O Hugging Face oferece uma documentação abrangente que inclui tutoriais e exemplos de como carregar e usar os modelos em Python, incluindo práticas recomendadas para trabalhar com LLMs e outras implementações de IA generativa.\n",
      "\n",
      "6. **Experimente modelos diretamente na interface**: O site também permite que você experimente alguns modelos diretamente no navegador, sem precisar programar, facilitando a interação com LLMs e outras aplicações de IA.\n",
      "\n",
      "Com esses passos, você poderá acessar e começar a usar os recursos disponíveis na Hugging Face, incluindo tanto modelos de linguagem de grande escala (LLMs) quanto outras inovações em IA generativa. Se precisar de exemplos adicionais de como integrar esses modelos em seus projetos, a documentação da Hugging Face é um ótimo recurso para começar.\n"
     ]
    }
   ],
   "source": [
    "chat_chain = RetrievalQA.from_chain_type(\n",
    "    llm=chat,\n",
    "    retriever=vectordb.as_retriever(search_type='mmr'),\n",
    "    chain_type='refine'\n",
    ")\n",
    "\n",
    "pergunta = 'O que é Hugging Face e como faço para acessá-lo?'\n",
    "resposta = chat_chain.invoke({'query': pergunta})\n",
    "print(resposta['result'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
